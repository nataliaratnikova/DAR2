#! /usr/bin/env python
"""
 DAR utilities
"""
# Created:  June, 15-17, 2003
#
__revision__ = "$Id: Utils.py,v 1.3 2006/01/18 21:18:53 ratnik Exp $"
__version__ = "$Revision: 1.3 $"

import os
import re
import sys
import time
import string
import shutil
import popen2
import commands

#############################
# DAR version control functions
#############################
darVersion = 'version unknown ' # hardcoded default
#global verbosityLevel
verbosityLevel = 1
def setDarVersion(vers):
    """
    setDarVersion:
      Sets global  DAR version
    """
    global darVersion
    darVersion = vers

def darVersionInFile ( filename ) :
    """
    darVersionInFile:
      Reads version  name from  the file
    """
    try:
        versFile = open ( filename )
        # Return only the first word:
        allLinesInFile = string.join ( versFile.readlines ( ) )
        versFile.close ( )
        return allLinesInFile.split ( None, 1 )[0]
    except:
        #return "DAR version unknown"
        warning("Could not get DAR version from file " + filename)
        return darVersion

def getDarVersion():
    """
    getDarVersion:
      DAR version
    """
    return darVersion

def usageError ( message, programName) :
    """
    usageError:
      Call it to quit in  case of usage error
    """
    if getVerbose():
        print "Usage error: ", message, \
              "\nTry \'" + programName + " -h\' for help"
    sys.exit ( 2 )

def readConfigFile ( conffile, configDict ) :
    """
    readConfigFile:
      Reads configuration  from file
    """
    # Read in the configuration:
    if os.path.exists ( conffile ) :
        infoOut ( "Reading DAR configuration setup from file: " + conffile ) 
        cnf = open ( conffile,'r' ) 
        for line in cnf.readlines ( ):
            process ( line, configDict ) 
        cnf.close (  ) 

def convertDAR2DAR2(arg,  mode, programName):
    """
    convertDAR2DAR2:
      Converts old-style dar arguments to dar input
      (similar to obtained from spec file )
    """
    darInput = [ '# Next  line is generated by automatic convertion ', \
                '# of old-style DAR input arguments\n']
    if mode == 'create':
        if os.path.isdir(arg ): 
            #  If first argument is a directory,  it is always considered
            # a SCRAM managed project,  for backward compatibility
            # with the old DAR.
            darInput.append( 'use scram rte '+arg )
        elif os.path.isfile(arg):
            # Read dar input from the specfile:
            specfile = open(arg, 'r')
            darInput = specfile.readlines()
        else:
            usageError("check  your first  argument :  " + \
                        " it should be either a directory or a file",
                       programName)
    elif mode=='install':
        # First argument specifies a darball. 
        if os.path.isfile(arg):
            darInput.append('use dar file '+arg)
    return  darInput

#############################
#  Output standardizing functions:
#############################

def setVerbose(level):
    """
    setVerbose:
    """
    # Default verbosity:
    global verbosityLevel
    verbosityLevel = level

def getVerbose ():
    """
    returns current verbosity level
    """
    return verbosityLevel
    
def strong(inputString):
    """
    strong:
      returns emphasized text string
    """
    return "\033[1m"+inputString+"\033[0m"

def banner():
    """
    banner:
      returns a banner string
    """
    if  getVerbose():
        print strong("CMS software distribution tool DAR")
    
def infoOut(infoString):
    """
    infoOut:
    """
    if getVerbose(): 
        print '\033[1mINFO\033[0m',  infoString
    # rdarwish:
    # what about this:
    #if getVerbose():
    #   print strong(INFO), infoString

def warning(warningString = None):
    """
    warning:
      print out  warnings
    """
    # to  add: collect all warnings in one logfile
    if getVerbose(): 
        mes = strong("WARNING:")+warningString    
        print(mes)
        
def stop():
    """
    stop:
    """
    sys.exit("STOP HERE")

def debug(debugString = '',  num = 0):
    """
    debug:
    """
    print strong (" !!!!! DEBUG  "+str(num)+" !!!!! :  "+debugString)

def readFileFromArchive(fileArchive,  filename,  bytes='1024k',  blocks='5'):
    """
    readFileFromArchive:
      Reads a portion of the tarball and returns the contents of the specified
      file extracted into STDOUT. The file should be found close to the beginning
      of the fileArchive. The optional blocks argument specifies the number of MB
      blocks to read. Default is  5MB, and it should be increased for bigger files. 
    """
    infoOut('reading file '+filename+' from fileArchive '+fileArchive)
    #cmd = 'dd  if= ' + fileArchive + ' bs=' + bytes + ' count=' + blocks + \
    #     ' 2> /dev/null | tar xz -O ' + filename + ' 2> /dev/null'
    cmd = 'dd if=' + fileArchive + \
          ' bs=' + bytes + ' count=' + blocks + \
          ' 2> /dev/null | tar xz -O ' + filename + ' 2> /dev/null'
    infoOut('Running cmd: ' + cmd)
    #infoOut(commands.getoutput(cmd))

    return commands.getoutput(cmd)
# Sine the  above command will always exit with non-zero  status,  because tar
# was not read to the end, some other check will be needed here that the
# extraction was successful!

#############################
#  String processing functions:
#############################

def process(line, todict, syntax = None):
    """
    process:
      Parses a file object, recognizes key = value pattern and ignores
      comments. Adds found pair to the dictionary
    """
    if syntax == "scramSh":
        scramSh = 1
    else:
        scramSh = 0
    # Discard comments
    line = re.sub('\t*#.*', '', line)
    # Compile recognized patterns:
    equality = re.compile('(.*)=(.*)')
    blankLine = re.compile('(\t*\n)')    
    if scramSh:
        # ignore "export variable;" lines
        exportVar = re.compile('export (.*);')
    # Match the key = value pattern
    result = equality.match(line)
    if result:
        key, value = result.groups()
        # discard surrounding whitespaces:
        key = string.strip(key)
        value = string.strip(value)
        if scramSh:
            # removes surrounding doublequotes and concluding semicolon:
            value = value[1:-2]
        # store a pair
        todict[key] = value
        return 0
    # All this is just to catch unrecognized lines:
    # Skip blank lines
    result = blankLine.match(line)
    # Ignore "export Var;" lines in scram syntax:
    if scramSh:
        result = exportVar.match(line)        
    if result:
        return 0
    else:
        print "unrecognized line: ",  line
        return 1    

def convertPatternList(patternList):
    """
    convertPatternList:
      returns converted list of patterns
    """
    # For backward compatibility with DAR-1, which accepted 
    # simple filenames patterns (without path or wildcard) :
    if type(patternList) == type(''):
        patternList = string.split(patternList, '\;')
    newList = []
    for pattern in patternList:
        if string.find(pattern, '*' ) < 0: # simple name
            # This handles slashes correctly:
            dirPattern = string.replace('*/'+pattern, '//', '/')
            filePattern = string.replace(dirPattern+'/*', '//', '/')
            conversion = [ dirPattern,  filePattern ]
            warning (" Converted old-style pattern "+ pattern + \
                    "   to:  "+ str ( conversion ) )
            newList.extend(conversion)
        else: 
            newList.append(pattern)
    return newList

################################
#  Files and directories related utilities:
################################

def notWritable(inputDir):
    """
    notWritable:
    """
    if not (os.path.isdir(inputDir)):
        return "No such directory: "+inputDir
    if not os.access(inputDir,  os.W_OK):
        return "No write permission in the directory: "+inputDir
    return

def notReadable(inputDir):
    """
    notReadable:
    """
    if not (os.path.isdir(inputDir)):
        return "No such directory: "+inputDir
    if not os.access(inputDir,  os.R_OK):
        return "Can not read in the directory: "+inputDir
    return

def spaceLeft (inputDir):
    """
    spaceLeft:
      returns the number of free KB in inputDir
    """
    # returns the number of free KB left in inputDir
    if  not os.path.isdir (inputDir):
        sys.exit ("spaceLeft ERROR: $inputDir is not a directory\n ")
    if not os.access(inputDir, os.W_OK):
        # It's not much sense to check space without a write permission ...
        warning('you have no write permission in $inputDir') # important warning
    dfOutput = popen2.popen2("df  --portability -k "+inputDir)[0].readlines()[1]
    if string.split(dfOutput)[0]=="AFS":
        # Use listquota to get space left in  AFS volume:
        lqOutputSplit = \
                        string.split\
                        (popen2.popen2 ("fs listquota "+ inputDir)[0].readlines()[1])
        if lqOutputSplit[1] == "no" and lqOutputSplit[2] == "limit":
            #There is no quota, so look at volume size
            lqOutputSplit = \
                        string.split\
                        (popen2.popen2 ("fs listquota "+ inputDir)[0].readlines()[1])
            dfOutput = popen2.popen2("fs diskfree " + inputDir)
            available = float(lqOutputSplit[3])
        else:
            available = float(lqOutputSplit[1]) - float(lqOutputSplit[2])
    else:
        available = float(string.split(dfOutput)[3])
    infoOut( "spaceLeft: "+str(available)+" KB free in directory "+inputDir)
    return available

def copySharedLibs(ldLibraryPath,  target,  lddCheck = 'yes'):
    """
    copySharedLibs:
    """
    curdir = os.getcwd()
    locations = string.split(ldLibraryPath, ':')
    locations.reverse()
    #print locations
    os.chdir(target)
    for directory in locations:
        if os.path.isdir(directory):
            for entry in os.listdir(directory):
                filename = directory+'/'+entry
                stat = os.system('ldd '+filename+' >& /dev/null')
                if ( stat == 0):
                    # put here mechanism for preserving links-aliases
                    # as Tony's script sometimes fails
                    if (os.path.islink(filename) and \
                        (string.find(os.readlink(filename), '/') == -1)):
                        os.symlink(os.readlink(filename),  entry)
                    else:
                        shutil.copyfile(filename,  target+'/'+entry)
                        shutil.copymode(filename,  target+'/'+entry)
    os.chdir(curdir)

def shortcut(fromDir, toDir):
    """
    shortcut:
    """
    # Returns shortest relative path from fromDir to toDir assuming
    # that both paths start from the same top directory
    path1 = string.split(canonicalPath(fromDir), "/")
    path2 = string.split(canonicalPath(toDir), "/")
    parentDirectory = ["../"]*(len(path1))
    down = path2
    for i in range(1, min(len(path1), len(path2))+1):
        if path1[0:i] == path2[0:i]:
            # Here we can shorten the path:
            parentDirectory = parentDirectory[1:]
            down = down[1:]
    return string.join(parentDirectory, '')+string.join(down, '/')

def commonPath(dir1, dir2):
    """
    commonPath:
      returns longest  common path  for  two  abs paths
    """
    result = ""
    path1 = string.split(canonicalPath(dir1[1:]), "/")  # strip leading /
    path2 = string.split(canonicalPath(dir2[1:]), "/")
    for i in range(len(path1)):
        if i >= len(path2):
            break
        if path1[i] != path2[i]:
            break
        result = "%s/%s" % (result, path1[i])
    return result

def eliminatePathDuplicates(path):
    """
    eliminatePathDuplicates:
    """
    pathsList = string.split(path, ':')
    pathsList.reverse()
    for path in pathsList:
        if pathsList.count(path) != 1:
            pathsList.remove(path)
    pathsList.reverse()
    path = string.join(pathsList, ':')
    return path
    
def stripPath (fromPath,  stripPath):
    """
    stripPath:
    """
    # cut common head from the path name
    if string.find(fromPath, stripPath):
        print "stripPath ERROR-> strip %s doesn't match %s" \
              % (fromPath,  stripPath)
        return None
    index = len(stripPath)+1
    return fromPath[index:]

def canonicalPath (path):
    """
    canonicalPath:
    """
    # remove "//",  "/" from the end etc
    result = path
    while string.find(path, "//") >= 0:
        string.replace(result,  "//", "/")
    while result[-1] == "/":
        result = result[:-1]
    return result

def noteSize(inputDir):
    """
    noteSize:
    """
    (status,  out) = commands.getstatusoutput(' du -ks '+inputDir)
    if status == 0: # successfull
        return int(string.split(out)[0])
    
def cleanup(cleanupDir,  outputFile = "Manifest.txt"):
    """
    cleanup:
      replaces all duplicated files in  directory dir by symbolic links;
      prints md5sum output for all entries into the outputFile
    """

    def md5visit(arg,  dirname,  files):
        """
        cleanup.md5visit:
          visiting routine that does all cleanup and md5sum work
        """
        for name in files:
            entry = os.path.join(dirname, name)
            if not os.path.exists(entry):
                print "WARNING: not existing entry",  entry
                break
            if os.path.isfile(entry): # can be also a symlink
                #incarnate(entry)
                (status,  out) = commands.getstatusoutput('md5sum '+entry)
                if status == 0: # normal termination
                    arg.oFile.write(out+"\n")
                    (md5,  filename) = string.split(out)
                    if arg.md5Dict.has_key(md5):                        
                        if getVerbose():
                            print "Linking "+ filename + " to "+ arg.md5Dict[md5]
                        # We already had this file, and can create a symlink:
                        (srcdir, srcname) = os.path.split(arg.md5Dict[md5])
                        # make it writable to  be able to unlink:
                        os.chmod(entry, 33204)
                        os.unlink(entry) # first remove it
                        os.chdir(dirname)
                        os.symlink(shortcut(dirname,  arg.md5Dict[md5]),  name)
                        os.chdir(arg.root) # better to be on the safe side
                    else:
                        arg.md5Dict[md5] = filename                        
    #######################
    # Here actions start:
    oFile = open(outputFile,  'w')
    arg = Bunch(
        md5Dict = {},
        oFile = oFile,
        root = cleanupDir)
    os.chdir(cleanupDir)     # All manipulations are done locally in the directory.
    os.path.walk('.',  md5visit,  arg)
    oFile.close()

###########################
# Python code facilitators:
###########################

class Lister:
    """
    class Lister:
    """

    def __init__(self):
        pass
    
    def __repr__(self):
        return ("<Instance of %s, address %s:\n%s>" %
                (self.__class__.__name__,       # my class's name
                 id(self),                      # my address
                 self.attrnames()) )            # name = value list

    def attrnames(self):
        """
        Lister.attrnames:
        """
        result = ''
        for attr in self.__dict__.keys():      # scan instance namespace dict
            if attr[:2] == '__':
                result = result+"\tattribute: %s=<built-in>\n" % attr
            else:
                result = result + \
                         "\tattribute: %s=%s\n" % (attr,  self.__dict__[attr])
        return result

class Bunch(Lister):
    """
    class Bunch:
      Can be used for groupping keyword arguments
    """
    def __init__(self,  **kwds):
        Lister.__init__(self)
        self.__dict__.update(kwds)

###########################
# Execution  helpers :
###########################

class Logger:
    """
    class Logger:
    """
    def __init__(self,  filename):
        self.filename = filename
    def __call__(self,  callString):
        filename = open(self.filename,  'a')
        filename.write('[' + time.asctime(time.localtime(time.time())) + '] ')
        filename.write(callString + '\n')
        filename.close()
        
    def logfileName(self):
        """logfileName"""
        return self.filename


class Session:
    """
    Session:
      creates shell session to allow execute consecutively commands in the
      same environment and control shell stdout inside the python program
    """
    def __init__(self, shell = '/bin/sh'):
        self.shell = shell
        self.r,  self.w = popen2.popen2(shell)
        self.commands = []
        self.allOut = []

    def run(self,  command,  errorCapture = None):
        """
        Session.run:
          Executes shell command in the session environment, 
          returns standard output and status
        """
        # Command stdout for further processing
        stdout = []
        # Support list of all commands in session. 
        # EOL is added.
        self.commands.append(command+'\n')
        print "Executing command \'"+command+"\'"
        # Add marker after command executed; use it to get the return status:
        self.w.write(command+"; echo finished with status $?;\n")
        pattern = re.compile(r'(.*)finished with status (.*)\n')
        # submitting command to shell:
        self.w.flush()
        while 1 :
            out = self.r.readline()
            match = pattern.match(out)
            if match:
                status = match.group(2)
                if status != "0":
                    print 'Finished with non-zero status',  status
                break
            stdout.append(out)
        self.r.flush()
        # Save output from all commands in session
        for i in range(len(stdout)):
            self.allOut.append(stdout[i])
        return stdout,  status

    def __del__(self):
        """ session destructor"""
        self.w.write("exit;\n")
        self.r.close ()
        self.w.close ()


#############################
# Exceptions handling
#############################

def DARInternalError(errorString = None):
    """
    DARInternalError
    """
    print strong("ERROR:") , \
          "Caught an exception\n type: ", \
          sys.exc_info()[0], \
          "\n value: ", \
          sys.exc_info()[1], \
          errorString
    sys.exit("DAR internal problem")

class Error(Exception):
    """
    class Error:
      Base class for exceptions in this module.
    """
    pass

class InputError(Error):
    """
    class InputError:
      Exception raised for errors in the input.
      Attributes:
        message -- explanation of the error
    """
    def __init__(self, message):
        self.message = message
        print strong("\nDAR Input Error:"), self.message, '\n\n'

class TransitionError(Error):
    """
    class TransitionError
      Raised when an operation attempts a state transition that's not
      allowed.

      Attributes:
        previous -- state at beginning of transition
        next -- attempted new state
        message -- explanation of why the specific transition is not allowed
    """

    def __init__(self,  previous,  next,  message):
        self.previous = previous
        self.next = next
        self.message = message

######################################
if __name__ == '__main__':
    print "\nTest convertPatternList\n"
    # Try erase pattern from refdbdarrc:
    erasePattern = "*.html\;datafiles\;*.ps\;*.pdf\;CVS\;" + \
                    "tmp\;rh73Gcc32Dbg\;doc\;lib*.a\;libqt-*\;" + \
                    "cms132.rz.gz\;cms12*\;cms131*\;*.C\;" + \
                    "rh73Gcc32dbx\;win32Vc71"
    print "\nOriginal erasePattern string:\n=======================\n",  \
          erasePattern
    print "\nConverted pattern list:\n=======================\n",  \
          convertPatternList(erasePattern)
    patterns = ['*.html',  'tmp',  'datafiles',  '*.ps',  '*.pdf',  'CVS', \
              'tmp', 'rh73Gcc32Dbg',  'doc',  'lib*.a',  'libqt-*',  \
              'cms132.rz.gz',  '*/cms12*']
    print "\nOriginal patterns list:\n=======================\n",  patterns
    print "\nConverted pattern list:\n=======================\n",  \
          convertPatternList(patterns)
    print "\nTest extract sfile from  archive\n"
    archive = \
            '/scratch/natasha/DAR2-TESTS/TMP/' + \
            '1097624206.96/non-scram-testDar.tar.gz'
    output = readFileFromArchive(archive,
                                 'non-scram-test/.DAR/Manifest.txt',
                                 blocks = '5')
    print output 
